{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tfidf_calculator import computeTF, computeIDF, computeTFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "with open('genia4ertraining/tokenized_sentences.txt','r',encoding='utf-8') as f:\n",
    "    #lines = f.read().rstrip().split('\\n')\n",
    "    for line in f:\n",
    "        if len(line.split())==0:\n",
    "            continue\n",
    "        sentence_list.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "with open('genia4ertraining/unigram_candidates.txt','r') as f:\n",
    "    for word in f:\n",
    "        #token = lemmatizer.lemmatize(word.strip())\n",
    "        candidates.append(word.strip())\n",
    "candidates = list(sorted(set(candidates)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlist = []\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "for sent in sentence_list:\n",
    "    tokens = sent.split()\n",
    "    #tokens = [lemmatizer.lemmatize(x) for x in tokens]\n",
    "    bowlist.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(np.arange(0,len(candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unis = dict(zip(candidates,indices))\n",
    "#unis['conditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmatrix = computeTF(unis,bowlist,sentence_list)\n",
    "vectorizer = TfidfTransformer()\n",
    "res = vectorizer.fit_transform(tfmatrix).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsums = np.array(np.sum(res,axis=0))\n",
    "finalsums = finalsums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0,len(finalsums)):\n",
    "    if finalsums[i]==0 or finalsums[i]==0.0:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldwords = []\n",
    "with open('genia4ertraining/unigram_goldstd.txt','r') as f:\n",
    "    for word in f:\n",
    "        #token = lemmatizer.lemmatize(word.strip())\n",
    "        goldwords.append(word.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list(zip(candidates,finalsums))\n",
    "scoresfinal = sorted(scores, key=lambda tup: tup[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in scores:\n",
    "    if tup[1]==0 or tup[1]==0.0:\n",
    "        print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_terms = scoresfinal[0:857]\n",
    "#pprint(pruned_terms)\n",
    "gold_len = len(goldwords)\n",
    "pruned_len = len(pruned_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = 0\n",
    "for tup in pruned_terms:\n",
    "\tif str(tup[0]) in goldwords:\n",
    "\t\tresults+=1\n",
    "\n",
    "precision = results/pruned_len\n",
    "recall = results/gold_len\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.2485414235705951\n",
      "recall 0.06857694784288473\n",
      "f1 0.10749432248296743\n"
     ]
    }
   ],
   "source": [
    "print('precision', precision)\n",
    "print('recall', recall)\n",
    "print('f1',2*precision*recall/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-a9e04c544fa7>\", line 14, in <module>\n",
      "    recall = results/gold_len\n",
      "NameError: name 'gold_len' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\anjali\\appdata\\local\\programs\\python\\python37\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gold_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "x = np.arange(1000,20000,1000)\n",
    "#print(x[0:10])\n",
    "\n",
    "y_p = []\n",
    "y_r = []\n",
    "for i in x:\n",
    "    pruned_terms = scoresfinal[0:i]\n",
    "    pruned_len = len(pruned_terms)\n",
    "    results = 0\n",
    "    for tup in pruned_terms:\n",
    "        if str(tup[0]) in goldwords:\n",
    "            results+=1\n",
    "    precision = results/pruned_len\n",
    "    recall = results/gold_len\n",
    "    y_p.append(precision)\n",
    "    y_r.append(recall)\n",
    "    \n",
    "plt.plot(x,y_p)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "plt.savefig('preck.png')\n",
    "plt.plot(x,y_r)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()\n",
    "plt.savefig('reck.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmax = x[np.argmax(np.array(y_p))]\n",
    "ymax = np.array(y_p).max()\n",
    "xmax\n",
    "#ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cell', 699.6346377852503),\n",
       " ('gene', 385.47509734981327),\n",
       " ('expression', 372.59361656805174),\n",
       " ('protein', 340.52278238097176),\n",
       " ('factor', 340.1913997642727),\n",
       " ('transcription', 308.34741166849795),\n",
       " ('activation', 308.07260337418774),\n",
       " ('human', 303.96907269459683),\n",
       " ('receptor', 257.885089229247),\n",
       " ('activity', 251.62017345982161),\n",
       " ('binding', 246.28611566380263),\n",
       " ('promoter', 220.88245888122407),\n",
       " ('NF-kappa', 200.37828850945718),\n",
       " ('site', 197.54875473757193),\n",
       " ('nuclear', 181.5070668077838),\n",
       " ('lymphocyte', 173.58655047077755),\n",
       " ('effect', 172.72051730947143),\n",
       " ('level', 169.64594436908627),\n",
       " ('line', 165.80314281707925),\n",
       " ('response', 158.8071100111228)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresfinal[0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
